{
 "cells": [
  {
   "cell_type": "code",
   "id": "0e9ad472",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    },
    "ExecuteTime": {
     "end_time": "2025-08-02T07:40:58.215459Z",
     "start_time": "2025-08-02T07:38:18.390855Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"danavery/urbansound8K\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\datasets--danavery--urbansound8K. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading data:   0%|          | 0/16 [00:00<?, ?files/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Downloading data:   6%|▋         | 1/16 [00:46<11:37, 46.53s/files]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Downloading data:   6%|▋         | 1/16 [01:40<25:03, 100.22s/files]\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\tqdm\\contrib\\concurrent.py:51\u001B[0m, in \u001B[0;36m_executor_map\u001B[1;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m PoolExecutor(max_workers\u001B[38;5;241m=\u001B[39mmax_workers, initializer\u001B[38;5;241m=\u001B[39mtqdm_class\u001B[38;5;241m.\u001B[39mset_lock,\n\u001B[0;32m     50\u001B[0m                   initargs\u001B[38;5;241m=\u001B[39m(lk,)) \u001B[38;5;28;01mas\u001B[39;00m ex:\n\u001B[1;32m---> 51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtqdm_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43miterables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\concurrent\\futures\\_base.py:609\u001B[0m, in \u001B[0;36mExecutor.map.<locals>.result_iterator\u001B[1;34m()\u001B[0m\n\u001B[0;32m    608\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 609\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    610\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\concurrent\\futures\\_base.py:441\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[1;32m--> 441\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\threading.py:312\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 312\u001B[0m     \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    313\u001B[0m     gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[1;32m----> 3\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdanavery/urbansound8K\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\load.py:1412\u001B[0m, in \u001B[0;36mload_dataset\u001B[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001B[0m\n\u001B[0;32m   1409\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m builder_instance\u001B[38;5;241m.\u001B[39mas_streaming_dataset(split\u001B[38;5;241m=\u001B[39msplit)\n\u001B[0;32m   1411\u001B[0m \u001B[38;5;66;03m# Download and prepare data\u001B[39;00m\n\u001B[1;32m-> 1412\u001B[0m \u001B[43mbuilder_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1414\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1415\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverification_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverification_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1416\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1417\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1418\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;66;03m# Build dataset for splits\u001B[39;00m\n\u001B[0;32m   1421\u001B[0m keep_in_memory \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1422\u001B[0m     keep_in_memory \u001B[38;5;28;01mif\u001B[39;00m keep_in_memory \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m is_small_dataset(builder_instance\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mdataset_size)\n\u001B[0;32m   1423\u001B[0m )\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\builder.py:894\u001B[0m, in \u001B[0;36mDatasetBuilder.download_and_prepare\u001B[1;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001B[0m\n\u001B[0;32m    892\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_proc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    893\u001B[0m     prepare_split_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_proc\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m num_proc\n\u001B[1;32m--> 894\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_download_and_prepare(\n\u001B[0;32m    895\u001B[0m     dl_manager\u001B[38;5;241m=\u001B[39mdl_manager,\n\u001B[0;32m    896\u001B[0m     verification_mode\u001B[38;5;241m=\u001B[39mverification_mode,\n\u001B[0;32m    897\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mprepare_split_kwargs,\n\u001B[0;32m    898\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdownload_and_prepare_kwargs,\n\u001B[0;32m    899\u001B[0m )\n\u001B[0;32m    900\u001B[0m \u001B[38;5;66;03m# Sync info\u001B[39;00m\n\u001B[0;32m    901\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mdataset_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(split\u001B[38;5;241m.\u001B[39mnum_bytes \u001B[38;5;28;01mfor\u001B[39;00m split \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39msplits\u001B[38;5;241m.\u001B[39mvalues())\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\builder.py:948\u001B[0m, in \u001B[0;36mDatasetBuilder._download_and_prepare\u001B[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001B[0m\n\u001B[0;32m    946\u001B[0m split_dict \u001B[38;5;241m=\u001B[39m SplitDict(dataset_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_name)\n\u001B[0;32m    947\u001B[0m split_generators_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001B[1;32m--> 948\u001B[0m split_generators \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_split_generators(dl_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msplit_generators_kwargs)\n\u001B[0;32m    950\u001B[0m \u001B[38;5;66;03m# Checksums verification\u001B[39;00m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verification_mode \u001B[38;5;241m==\u001B[39m VerificationMode\u001B[38;5;241m.\u001B[39mALL_CHECKS \u001B[38;5;129;01mand\u001B[39;00m dl_manager\u001B[38;5;241m.\u001B[39mrecord_checksums:\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\packaged_modules\\parquet\\parquet.py:49\u001B[0m, in \u001B[0;36mParquet._split_generators\u001B[1;34m(self, dl_manager)\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAt least one data file must be specified, but got data_files=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mdata_files\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     48\u001B[0m dl_manager\u001B[38;5;241m.\u001B[39mdownload_config\u001B[38;5;241m.\u001B[39mextract_on_the_fly \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 49\u001B[0m data_files \u001B[38;5;241m=\u001B[39m \u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_and_extract\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_files\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m splits \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m split_name, files \u001B[38;5;129;01min\u001B[39;00m data_files\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\download\\download_manager.py:326\u001B[0m, in \u001B[0;36mDownloadManager.download_and_extract\u001B[1;34m(self, url_or_urls)\u001B[0m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdownload_and_extract\u001B[39m(\u001B[38;5;28mself\u001B[39m, url_or_urls):\n\u001B[0;32m    311\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Download and extract given `url_or_urls`.\u001B[39;00m\n\u001B[0;32m    312\u001B[0m \n\u001B[0;32m    313\u001B[0m \u001B[38;5;124;03m    Is roughly equivalent to:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;124;03m        extracted_path(s): `str`, extracted paths of given URL(s).\u001B[39;00m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mextract(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl_or_urls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\download\\download_manager.py:159\u001B[0m, in \u001B[0;36mDownloadManager.download\u001B[1;34m(self, url_or_urls)\u001B[0m\n\u001B[0;32m    157\u001B[0m start_time \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mnow()\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m stack_multiprocessing_download_progress_bars():\n\u001B[1;32m--> 159\u001B[0m     downloaded_path_or_paths \u001B[38;5;241m=\u001B[39m \u001B[43mmap_nested\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdownload_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl_or_urls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmap_tuple\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDownloading data files\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m duration \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mnow() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[0;32m    169\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading took \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mduration\u001B[38;5;241m.\u001B[39mtotal_seconds()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m60\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m min\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\utils\\py_utils.py:503\u001B[0m, in \u001B[0;36mmap_nested\u001B[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001B[0m\n\u001B[0;32m    501\u001B[0m     num_proc \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(v, types) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(v) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m iterable):\n\u001B[1;32m--> 503\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    504\u001B[0m         map_nested(\n\u001B[0;32m    505\u001B[0m             function\u001B[38;5;241m=\u001B[39mfunction,\n\u001B[0;32m    506\u001B[0m             data_struct\u001B[38;5;241m=\u001B[39mobj,\n\u001B[0;32m    507\u001B[0m             num_proc\u001B[38;5;241m=\u001B[39mnum_proc,\n\u001B[0;32m    508\u001B[0m             parallel_min_length\u001B[38;5;241m=\u001B[39mparallel_min_length,\n\u001B[0;32m    509\u001B[0m             batched\u001B[38;5;241m=\u001B[39mbatched,\n\u001B[0;32m    510\u001B[0m             batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m    511\u001B[0m             types\u001B[38;5;241m=\u001B[39mtypes,\n\u001B[0;32m    512\u001B[0m         )\n\u001B[0;32m    513\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m    514\u001B[0m     ]\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m num_proc \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m num_proc \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;241m<\u001B[39m parallel_min_length:\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m batched:\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\utils\\py_utils.py:504\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    501\u001B[0m     num_proc \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(v, types) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(v) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m iterable):\n\u001B[0;32m    503\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m--> 504\u001B[0m         \u001B[43mmap_nested\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m            \u001B[49m\u001B[43mparallel_min_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparallel_min_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    512\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    513\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m    514\u001B[0m     ]\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m num_proc \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m num_proc \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;241m<\u001B[39m parallel_min_length:\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m batched:\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\utils\\py_utils.py:520\u001B[0m, in \u001B[0;36mmap_nested\u001B[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001B[0m\n\u001B[0;32m    518\u001B[0m         batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m num_proc \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;241m%\u001B[39m num_proc \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    519\u001B[0m     iterable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(iter_batched(iterable, batch_size))\n\u001B[1;32m--> 520\u001B[0m mapped \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    521\u001B[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    522\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m hf_tqdm(iterable, disable\u001B[38;5;241m=\u001B[39mdisable_tqdm, desc\u001B[38;5;241m=\u001B[39mdesc)\n\u001B[0;32m    523\u001B[0m ]\n\u001B[0;32m    524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[0;32m    525\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [mapped_item \u001B[38;5;28;01mfor\u001B[39;00m mapped_batch \u001B[38;5;129;01min\u001B[39;00m mapped \u001B[38;5;28;01mfor\u001B[39;00m mapped_item \u001B[38;5;129;01min\u001B[39;00m mapped_batch]\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\utils\\py_utils.py:521\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    518\u001B[0m         batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m num_proc \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;241m%\u001B[39m num_proc \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    519\u001B[0m     iterable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(iter_batched(iterable, batch_size))\n\u001B[0;32m    520\u001B[0m mapped \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m--> 521\u001B[0m     \u001B[43m_single_map_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    522\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m hf_tqdm(iterable, disable\u001B[38;5;241m=\u001B[39mdisable_tqdm, desc\u001B[38;5;241m=\u001B[39mdesc)\n\u001B[0;32m    523\u001B[0m ]\n\u001B[0;32m    524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[0;32m    525\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [mapped_item \u001B[38;5;28;01mfor\u001B[39;00m mapped_batch \u001B[38;5;129;01min\u001B[39;00m mapped \u001B[38;5;28;01mfor\u001B[39;00m mapped_item \u001B[38;5;129;01min\u001B[39;00m mapped_batch]\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\utils\\py_utils.py:389\u001B[0m, in \u001B[0;36m_single_map_nested\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m    382\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m function(data_struct)\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    384\u001B[0m     batched\n\u001B[0;32m    385\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mdict\u001B[39m)\n\u001B[0;32m    386\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, types)\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, (\u001B[38;5;28mdict\u001B[39m, types)) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m data_struct)\n\u001B[0;32m    388\u001B[0m ):\n\u001B[1;32m--> 389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [mapped_item \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m iter_batched(data_struct, batch_size) \u001B[38;5;28;01mfor\u001B[39;00m mapped_item \u001B[38;5;129;01min\u001B[39;00m function(batch)]\n\u001B[0;32m    391\u001B[0m \u001B[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001B[39;00m\n\u001B[0;32m    392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m rank \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m logging\u001B[38;5;241m.\u001B[39mget_verbosity() \u001B[38;5;241m<\u001B[39m logging\u001B[38;5;241m.\u001B[39mWARNING:\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\utils\\py_utils.py:389\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    382\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m function(data_struct)\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    384\u001B[0m     batched\n\u001B[0;32m    385\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mdict\u001B[39m)\n\u001B[0;32m    386\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, types)\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, (\u001B[38;5;28mdict\u001B[39m, types)) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m data_struct)\n\u001B[0;32m    388\u001B[0m ):\n\u001B[1;32m--> 389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [mapped_item \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m iter_batched(data_struct, batch_size) \u001B[38;5;28;01mfor\u001B[39;00m mapped_item \u001B[38;5;129;01min\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[0;32m    391\u001B[0m \u001B[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001B[39;00m\n\u001B[0;32m    392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m rank \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m logging\u001B[38;5;241m.\u001B[39mget_verbosity() \u001B[38;5;241m<\u001B[39m logging\u001B[38;5;241m.\u001B[39mWARNING:\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\datasets\\download\\download_manager.py:206\u001B[0m, in \u001B[0;36mDownloadManager._download_batched\u001B[1;34m(self, url_or_filenames, download_config)\u001B[0m\n\u001B[0;32m    201\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    202\u001B[0m     max_workers \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    203\u001B[0m         config\u001B[38;5;241m.\u001B[39mHF_DATASETS_MULTITHREADING_MAX_WORKERS \u001B[38;5;28;01mif\u001B[39;00m size \u001B[38;5;241m<\u001B[39m (\u001B[38;5;241m20\u001B[39m \u001B[38;5;241m<<\u001B[39m \u001B[38;5;241m20\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    204\u001B[0m     )  \u001B[38;5;66;03m# enable multithreading if files are small\u001B[39;00m\n\u001B[1;32m--> 206\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mthread_map\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    207\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdownload_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    208\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl_or_filenames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_desc\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDownloading\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[43m        \u001B[49m\u001B[43munit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfiles\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmultiprocessing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_identity\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# contains the ranks of subprocesses\u001B[39;49;00m\n\u001B[0;32m    212\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menviron\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHF_DATASETS_STACK_MULTIPROCESSING_DOWNLOAD_PROGRESS_BARS\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m    213\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmultiprocessing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_identity\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtqdm_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtqdm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    219\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_download_single(url_or_filename, download_config\u001B[38;5;241m=\u001B[39mdownload_config)\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m url_or_filename \u001B[38;5;129;01min\u001B[39;00m url_or_filenames\n\u001B[0;32m    222\u001B[0m     ]\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\tqdm\\contrib\\concurrent.py:69\u001B[0m, in \u001B[0;36mthread_map\u001B[1;34m(fn, *iterables, **tqdm_kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;124;03mEquivalent of `list(map(fn, *iterables))`\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;124;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;124;03m    [default: max(32, cpu_count() + 4)].\u001B[39;00m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mconcurrent\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfutures\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ThreadPoolExecutor\n\u001B[1;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _executor_map(ThreadPoolExecutor, fn, \u001B[38;5;241m*\u001B[39miterables, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtqdm_kwargs)\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\site-packages\\tqdm\\contrib\\concurrent.py:51\u001B[0m, in \u001B[0;36m_executor_map\u001B[1;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ensure_lock(tqdm_class, lock_name\u001B[38;5;241m=\u001B[39mlock_name) \u001B[38;5;28;01mas\u001B[39;00m lk:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;66;03m# share lock in case workers are already using `tqdm`\u001B[39;00m\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m PoolExecutor(max_workers\u001B[38;5;241m=\u001B[39mmax_workers, initializer\u001B[38;5;241m=\u001B[39mtqdm_class\u001B[38;5;241m.\u001B[39mset_lock,\n\u001B[0;32m     50\u001B[0m                       initargs\u001B[38;5;241m=\u001B[39m(lk,)) \u001B[38;5;28;01mas\u001B[39;00m ex:\n\u001B[1;32m---> 51\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(tqdm_class(ex\u001B[38;5;241m.\u001B[39mmap(fn, \u001B[38;5;241m*\u001B[39miterables, chunksize\u001B[38;5;241m=\u001B[39mchunksize), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\concurrent\\futures\\_base.py:637\u001B[0m, in \u001B[0;36mExecutor.__exit__\u001B[1;34m(self, exc_type, exc_val, exc_tb)\u001B[0m\n\u001B[0;32m    636\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, exc_type, exc_val, exc_tb):\n\u001B[1;32m--> 637\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshutdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwait\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    638\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\concurrent\\futures\\thread.py:235\u001B[0m, in \u001B[0;36mThreadPoolExecutor.shutdown\u001B[1;34m(self, wait, cancel_futures)\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m wait:\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads:\n\u001B[1;32m--> 235\u001B[0m         \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\threading.py:1060\u001B[0m, in \u001B[0;36mThread.join\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1057\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot join current thread\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1059\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1060\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1061\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1062\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[0;32m   1063\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n\u001B[0;32m   1064\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_tstate_lock(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmax\u001B[39m(timeout, \u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32md:\\anaconda\\anaconda\\envs\\tf\\lib\\threading.py:1080\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m   1077\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   1079\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1080\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1081\u001B[0m         lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m   1082\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e5a76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10e7b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
